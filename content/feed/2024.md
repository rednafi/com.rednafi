---
title: "2024"
layout: post
ShowToc: false
editPost:
    disabled: true
hideMeta: true
ShowShareButtons: false
---

### September 04

#### [On the importance of ablation studies in deep learning research — François Chollet][5]

This is true for almost any engineering effort. It's always a good idea to ask if the design
can be simplified without losing usability. Now I know there's a name for this practice:
ablation study.

> _The goal of research shouldn't be merely to publish, but to generate reliable knowledge.
> Crucially, understanding causality in your system is the most straightforward way to
> generate reliable knowledge. And there's a very low-effort way to look into causality:
> ablation studies. Ablation studies consist of systematically trying to remove parts of a
> system-making it simpler—to identify where its performance actually comes from. If you
> find that X + Y + Z gives you good results, also try X, Y, Z, X + Y, X + Z, and Y + Z, and
> see what happens._

> _If you become a deep learning researcher, cut through the noise in the research process:
> do ablation studies for your models. Always ask, "Could there be a simpler explanation? Is
> this added complexity really necessary? Why?_

### September 01

#### [Why A.I. Isn’t Going to Make Art — Ted Chiang, The New Yorker][4]

I indiscriminately devour almost everything Ted Chiang puts out, and this piece is no
exception. It's one of the most articulate arguments I've read on the sentimental value of
human-generated artifacts, even when AI can make perfect knockoffs.

I'm pro-LLMs and use them to aid my work all the time. While they're incredibly useful for a
certain genre of tasks, buying into the Silicon Valley idea that these are soon going to
replace every type of human-generated content is incredibly naive and redolent of the hubris
within the tech bubble.

> _Art is notoriously hard to define, and so are the differences between good art and bad
> art. But let me offer a generalization: art is something that results from making a lot of
> choices. This might be easiest to explain if we use fiction writing as an example. When
> you are writing fiction, you are—consciously or unconsciously—making a choice about almost
> every word you type; to oversimplify, we can imagine that a ten-thousand-word short story
> requires something on the order of ten thousand choices. When you give a generative-A.I.
> program a prompt, you are making very few choices; if you supply a hundred-word prompt,
> you have made on the order of a hundred choices._

> _Generative A.I. appeals to people who think they can express themselves in a medium
> without actually working in that medium. But the creators of traditional novels,
> paintings, and films are drawn to those art forms because they see the unique expressive
> potential that each medium affords. It is their eagerness to take full advantage of those
> potentialities that makes their work satisfying, whether as entertainment or as art._

> _Any writing that deserves your attention as a reader is the result of effort expended by
> the person who wrote it. Effort during the writing process doesn’t guarantee the end
> product is worth reading, but worthwhile work cannot be made without it._

> _Some individuals have defended large language models by saying that most of what human
> beings say or write isn’t particularly original. That is true, but it’s also irrelevant.
> When someone says “I’m sorry” to you, it doesn’t matter that other people have said sorry
> in the past; it doesn’t matter that “I’m sorry” is a string of text that is statistically
> unremarkable. If someone is being sincere, their apology is valuable and meaningful, even
> though apologies have previously been uttered. Likewise, when you tell someone that you’re
> happy to see them, you are saying something meaningful, even if it lacks novelty._

### August 31

#### [How to Be a Better Reader — Tina Jordan, The NY Times][3]

> _To read more deeply, to do the kind of reading that stimulates your imagination, the
> single most important thing to do is take your time. You can’t read deeply if you’re
> skimming. As the writer Zadie Smith has said, “When you practice reading, and you work at
> a text, it can only give you what you put into it.”_

> _At a time when most of us read in superficial, bite-size chunks that prize quickness —
> texts, tweets, emails — it can be difficult to retrain your brain to read at an unhurried
> pace, but it is essential. In “Slow Reading in a Hurried Age,” David Mikics writes that
> “slow reading changes your mind the way exercise changes your body: A whole new world will
> open up, you will feel and act differently, because books will be more open and alive to
> you.”_

---

### August 26

#### [Dark Matter — Blake Crouch][1]

I just finished the book. It’s an emotional rollercoaster of a story, stemming from a
MacGuffin that enables quantum superposition in the macro world, bringing the Copenhagen
interpretation of quantum mechanics to life.

While the book starts off with a bang, it becomes a bit more predictable as the story
progresses. I still enjoyed how well the author reified the probable dilemma that having
access to the multiverse might pose. Highly recommened. I’m already beyond excited to read
his next book, [Recursion][2].

---

[5]: https://x.com/fchollet/status/1831029432653599226
[4]: https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art
[3]: https://www.nytimes.com/explain/2022/how-to-be-a-better-reader
[2]: https://www.goodreads.com/book/show/42046112-recursion
[1]:
    https://www.goodreads.com/book/show/27833670-dark-matter?ac=1&from_search=true&qid=rTnd5yTPS5&rank=1
